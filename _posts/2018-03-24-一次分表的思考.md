---
layout:     post
title:      一次分表的思考
subtitle:   一次分表的思考
date:       2018-03-24
author:     wind
header-img: img/post-bg-re-vs-ng1.jpg
catalog: true
tags:
    - Blog
---
# 一次分表问题的思考
## 背景
项目中因为用户角色权限模块设计不合理，导致角色和权限资源关联表生成了大量数据，影响了访问速度，因此考虑进行水平分表

## 分表工具
关于分表工具，主要有一些重量级的中间件如 mycat,cobar 等等，考虑到不想业务改动过大，以及对代码侵入小，直接使用轻量级的 sharding-jdbc

##  分表主键的选择
分表后要考虑多个表主键唯一，所以数据库的主键生成方式就需要考虑新的方式
- 使用数据库自增，不同表不同步长（使用数据库生成主键这个 基本淘汰了，不考虑）
- 使用UUID 长度较长，无序，比较占用空间（目前使用的是 hibernate 框架，且主键策略刚好为UUID ，就选用此方式了）
- 雪花算法  64位=1(确保正数)+41（时间戳）+5（机房id)+5(机器id)+12（同一时刻的序列号），方式比较好，就是分布式的时候机器时钟需要同步

## 切分规则
- 使用创建时间切分（这个扩容比较容易，不用挪动旧数据，就是可能冷热不均匀，旧数据一直没人访问）
- 使用某个字段取模均分（这个扩容比较麻烦 ，考虑到业务上来说我们最多使用的场景是使用角色id ,roleId来查询，刚好能够定位到具体的切片表中，所以最终 roleId.hash%64 分成了64张表
- 比较好的切割分时是一致性hash算法，扩容时候需要挪动的数据较少


## sharding-jdbc机制和问题
### sql 分页改写
sharing-jdbc 原理上来将原 sql 进行了改写，确保保证能路由到指定的分片或者从不同分片表中取出数据然后聚合返回，比较麻烦的是 分页sql 的改写，因为分页数据一般需要先排序再取出第几页
- shardin-jdbc 改写逻辑
查询第n页数据：先从各分表中获取0-n页数据，然后汇总排序后取出第n页数据即为最终结果，这个方式在页数较大的时候需要查询的数据非常多
- 业务折中的方式
禁止跨页，拿一页的time_max 最大值作为下一页的条件
- 二次查询
这个是比较好的方式，就是实现比较麻烦
（1）将order by time offset X limit Y，改写成order by time offset X/N limit Y
（2）找到最小值time_min
（3）between二次查询，order by time between $time_min and $time_i_max
（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset
（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y
缺点：
1. 当分表数为N时, 查一页数据要执行N*2条sql.(这个无解, 只要分表了就必须这样)
2. 当offset很大的时候, 第一次查询中扫描offset行数据依然会非常的慢, 如果只分表不分库的话, 那么一次查询会在一个库中产生N条慢sql
3. 算法实现起来代码逻辑应该不简单, 如果为了一个分页功能写这么复杂的逻辑, 是不是划不来,
而且后期也不好维护

###  离线计算+有损服务
分表后做分页查询时非常麻烦的，有没有别的思路呢？
分表是为了读负载，考虑引入汇总表：
1.正常业务读写分表
2.根据业务需求，实时计算/离线计算（sprak,kafak等）生成分表汇总表
3.分页查询汇总表
方案缺点：允许时延，汇总表只生成必要的数据字段

### 不分表，分区（tidb  mongodb es）
mysql5.5之前  大概500W需要分表
mysql5.5之后  大概1000w-2000w之后才需要
mysql 5.1后支持分区，生成多个 idb 文件
-  分区方式：rang  list   hash key
分表带来的逻辑复杂度很大，可考虑分区，分而治之
















